# Evolutionary Algorithms
![Evolutionary Algorithm](https://eodev.sourceforge.net/Evolutionary_algorithm.png)

EA (Evolutionary Algorithms) are a type of optimization algorithms which uses mechanisms inspired by biological evolution, such as reproduction, selection, mutation and recombination, etc. The general idea behind evolutionary algorithms is to start with a population of candidate solutions to a problem and then apply the operators like mutation, reproduction, etc to generate new solutions, hoping that the quality of solutions will improve over time. The fitness of an individual is defined by how well it solves the problem in the end. The individuals with best fitness will be getting selected for reproduction. The reproduction process involves creating new individuals by combining the traits of two or more selected individuals. This is done through crossover (swapping or combining genetic information) and mutation (introducing small random changes to an individual's genetic information). This process is repeated until a satisfactory solution is found or a stopping criterion is met. In most real applications of EAs, computational complexity (fitness function evaluation) is a prohibiting factor.The main advantage of evolutionary algorithms is their ability to explore a large search space of potential solutions in a relatively short amount of time, while avoiding getting stuck in local optima.

![EA types](https://slideplayer.com/slide/6644344/23/images/13/Evolutionary+Algorithms+Family.jpg)

# Genetic Algorithm
GA (Genetic ALgorithm) is a subset of EA. In GA a fewer genetic operators are applied compared to EA. GA are a specific type of evolutionary algorithm that is tailored towards problems with a discrete or binary solution space. Let us take an example of a knapsack problem where we have to stuff items in our bag given the maximum weight capacity of the bag. Here each item will be associated with either 0 or 1, where 1 means stuffed and 0 means unstuffed. So, the population will be a string of 0s and 1s given that the items are always in the same order. Here the fitness function will be maximum weight associated with the binary string and the weight should not exceed the weight limit set by the problem. The GA will select parents for next generation of population based upon the fitness of current population. After the parents selection the genes or traits which basically are 0s and 1s are mixed together. After mixing a small mutation is done on the string like a 0 is changed to 1 or vice versa. This process is repeated till a satisfactory solution is found or a stopping criterion is met.

![GA](https://2900157524-files.gitbook.io/~/files/v0/b/gitbook-legacy-files/o/assets%2F-LZMLRvaju5sqPs7pYTX%2F-Ltv4uFdHxY7yt_MdVwX%2F-LrPm3TI57kjTUXtuCts%2Fwhatisgenetic3.png?generation=1574023185419913&alt=media)

# NeuroEvolution of Augmenting Topology
![NEAT](https://www.investopedia.com/thmb/5-hnhHpOzLM2GVXPlSstg8tJYLw=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/dotdash_Final_Neural_Network_Apr_2020-01-5f4088dfda4c49d99a4d927c9a3a5ba0.jpg)

NEAT (NeuroEvolution of Augmenting Topology) is a type of GA. Now this dude is actually a stud. NeuroEvolution means evolving neurons? And augmenting, as said by google "make something greater by adding to it" And topology means the way in which constituent parts are arranged. So taking all these definitions and putting them together NEAT should mean something like Evolving Neurons by adding something to their arrangements? Yes, but replace the word neurons with neural network and Voil√†! Now that we know the definition let me explain how this dude is actually a stud of the group, Unlike traditional machine learning methods where the topology of a neural network is fixed before training, This bad boy can evolve the topology of the network during training. And along with changing the connections of the nerual network it also helps in optimizing the weights and avoids getting stuck in the local optima and it offers many more advantages but lets stop here and compare it to GA. So let's explore why is this dude so much better than GA when it is said to be a part of GA. So does GA have those fancy circles connecting to more fancy circles for i/o called neural networks? Nope. Will the solution found by GA work for another not-so-same input? Nope. Fitness Function Evaluation? Sometimes the data GA need to process for evaluation of its fitness function is so big than it becomes very complex and time consuming. So yeah the biggest flex of NEAT over GA (according to me atleast) is that it has the ability to deal with randomly generated inputs.

Resources:

https://www.youtube.com/watch?v=ovIykchkW5I and ChatGPT
![DONKEY KONG](https://p6.focus.de/img/fotos/id_498250/dig-donkey-kong.jpg?im=Crop%3D%280%2C138%2C1500%2C1124%29%3BResize%3D%28731%29&impolicy=perceptual&quality=medium&hash=068c4887a116d549d4b4ebcecb7de8ab78eaf1815bccfe48aa07f1862dcf2805)
